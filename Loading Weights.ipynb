{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ead3b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b967db8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloaders, loss_fn, acc_fn, random_state=49, epochs=1):\n",
    "    \n",
    "    \n",
    "    torch.manual_seed(random_state)\n",
    "    np.random.seed(random_state)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "    start = time.time()                                        #Initialize time to calculate time it takes to train model\n",
    "    model.to(device)                                               #Move model to GPU     \n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    counter=0\n",
    "    test_loss = []                         #Running training and validation loss\n",
    "    loss_epoch, f1_epoch = [0],[0]\n",
    "    AP_epoch =[0]\n",
    "    loss_list = []\n",
    "    times     = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start_epoch = time.time()\n",
    "        print(f'Epoch {epoch}')\n",
    "        #print(scheduler.get_last_lr())\n",
    "    \n",
    "\n",
    " ################ MODEL TESTING  #############################\n",
    "\n",
    "        dataloader = dataloaders['test']         #get the training data\n",
    "\n",
    "        step = 0\n",
    "        loss_test = []\n",
    "        f1=[]\n",
    "        AP = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloader:\n",
    "                x, y = inputs.to(device), labels.to(device)\n",
    "                #optimizer.zero_grad()                                   # zero the gradients\n",
    "                outputs = model(x)                                      #get model output for a given input\n",
    "\n",
    "                #################Metrics###################\n",
    "                f1.append(acc_fn(outputs, y).cpu().detach().numpy())\n",
    "                AP.append(average_precision_score(y.reshape(-1).cpu().detach().numpy(),  outputs.reshape(-1).cpu().detach().numpy()))\n",
    "                loss_test.append(loss_fn(outputs, y).cpu().detach().numpy())\n",
    "            ############################################\n",
    "                print(f'Current step: {step}, AllocMem (Mb): {torch.cuda.memory_allocated()/1024/1024:.3f},  F1: {np.mean(f1):.3f},  AP: {np.mean(AP):.3f}') \n",
    "\n",
    "                step+=1\n",
    "                ##################Calculate Loss, backprop, and update###############\n",
    "               \n",
    "                test_loss.append(loss_test[-1])\n",
    "        loss_epoch.append(np.mean(loss_test))\n",
    "        f1_epoch.append(np.mean(f1))\n",
    "        AP_epoch.append(np.mean(AP))\n",
    "        print()\n",
    "        print()\n",
    "        print(f' Loss test: {loss_epoch[-1]:.3f}, F-Score test:{f1_epoch[-1]:.3f}, AP val:{AP_epoch[-1]:.3f} \\n') \n",
    "        ######################################################################\n",
    "\n",
    "        epoch+=1\n",
    "        \n",
    "    return {\n",
    "            'f1_epoch':f1_epoch,\n",
    "            'Epochs': epoch}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7beb510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class basic_block(nn.Module):\n",
    "    def __init__(self,in_channels,out_chan, random_state=0):\n",
    "        super(basic_block,self).__init__()\n",
    "\n",
    "        out_channels = out_chan//2\n",
    "        \n",
    "        torch.manual_seed(random_state)\n",
    "        self.bn1         = nn.BatchNorm2d(in_channels)\n",
    "        \n",
    "        self.conv1x1_1_1 = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        self.bn2         = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv1x1_1_3 = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        self.bn3         = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv3x3_1   = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.bn4         = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv1x1_1_5 = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        self.bn5         = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv5x5_1   = nn.Conv2d(out_channels,out_channels,5,padding=2)\n",
    "        self.bn6         = nn.BatchNorm2d(out_channels)\n",
    "      \n",
    "        self.conv1x1_1_7 = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        self.bn7         = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv7x7_1   = nn.Conv2d(out_channels,out_channels,7,padding=3)\n",
    "        self.bn8         = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.bn9         = nn.BatchNorm2d(out_channels*4)\n",
    "        self.conv1x1_2_1 = nn.Conv2d(out_channels*4, out_channels, 1)\n",
    "        self.bn10        = nn.BatchNorm2d(out_channels)\n",
    "        self.conv1x1_2_3 = nn.Conv2d(out_channels*4, out_channels, 1)\n",
    "        self.bn11        = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3x3_2   = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.bn12        = nn.BatchNorm2d(out_channels)\n",
    "        self.conv1x1_2_5 = nn.Conv2d(out_channels*4, out_channels, 1)\n",
    "        self.bn13        = nn.BatchNorm2d(out_channels)\n",
    "        self.conv5x5_2   = nn.Conv2d(out_channels,out_channels,5,padding=2)\n",
    "        self.bn14        = nn.BatchNorm2d(out_channels)\n",
    "        self.conv1x1_2_7 = nn.Conv2d(out_channels*4, out_channels, 1)\n",
    "        self.bn15        = nn.BatchNorm2d(out_channels)\n",
    "        self.conv7x7_2   = nn.Conv2d(out_channels,out_channels,7,padding=3)\n",
    "        self.bn16        = nn.BatchNorm2d(out_channels)\n",
    "       \n",
    "    def forward(self, x):\n",
    "       \n",
    "        bn1         = self.bn1(x)\n",
    "        conv1x1_1_3 = self.bn3(self.conv1x1_1_3(bn1))\n",
    "        conv1x1_1_5 = self.bn4(self.conv1x1_1_5(bn1))\n",
    "        conv1x1_1_7 = self.bn5(self.conv1x1_1_7(bn1))\n",
    "        conv1x1_1_1 = F.relu(self.bn2(self.conv1x1_1_1(bn1)))\n",
    "        conv3x3_1   = F.relu(self.bn6(self.conv3x3_1(conv1x1_1_3)))\n",
    "        conv5x5_1   = F.relu(self.bn7(self.conv5x5_1(conv1x1_1_5)))\n",
    "        conv7x7_1   = F.relu(self.bn8(self.conv7x7_1(conv1x1_1_7)))\n",
    "        cat1        = torch.cat([conv1x1_1_1,conv3x3_1,conv5x5_1,conv7x7_1],dim=1)\n",
    "       \n",
    "        bn9         = self.bn9(cat1)\n",
    "        conv1x1_2_3 = self.bn11(self.conv1x1_2_3(bn9))\n",
    "        conv1x1_2_5 = self.bn12(self.conv1x1_2_5(bn9))\n",
    "        conv1x1_2_7 = self.bn13(self.conv1x1_2_7(bn9))\n",
    "        conv1x1_2_1 = F.relu(self.bn10(self.conv1x1_2_1(bn9)))\n",
    "        conv3x3_2   = F.relu(self.bn14(self.conv3x3_2(conv1x1_2_3)))\n",
    "        conv5x5_2   = F.relu(self.bn15(self.conv5x5_2(conv1x1_2_5)))\n",
    "        conv7x7_2   = F.relu(self.bn16(self.conv7x7_2(conv1x1_2_7)))\n",
    "        cat2        = torch.cat([conv1x1_2_1,conv3x3_2,conv5x5_2,conv7x7_2],dim=1)\n",
    "\n",
    " \n",
    "        return cat2\n",
    "       \n",
    "\n",
    "class UNET_multiscale2(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels= 1, init_features=32, random_state=0):\n",
    "        super(UNET_multiscale2, self).__nit__()\n",
    "        torch.manual_seed(random_state)\n",
    "        features = init_features\n",
    "        self.layer1 =  basic_block(in_channels,features)\n",
    "        self.down1  = nn.Conv2d(features*2,features,2,stride=2)\n",
    "       \n",
    "        self.layer2 = basic_block(features,features) \n",
    "        self.down2  = nn.Conv2d(features*2,features*2,2,stride=2)\n",
    "\n",
    "        self.layer3 = basic_block(features*2,features*2) \n",
    "        self.down3  = nn.Conv2d(features*4,features*4,2,stride=2)\n",
    "\n",
    "        self.layer4 = basic_block(features*4,features*4)\n",
    "        self.down4  = nn.Conv2d(features*8,features*8,2,stride=2)\n",
    "       \n",
    "        self.bottleneck = basic_block(features*8,features*8)\n",
    "        self.bn6     = nn.BatchNorm2d(features*8*2)\n",
    "        self.up1     = nn.ConvTranspose2d(features*16, features*8, 2, stride=2)\n",
    "             \n",
    "        self.layer6  = basic_block(features*16,features*4)      \n",
    "        self.bn7     = nn.BatchNorm2d(features*4*2)\n",
    "        self.up2     = nn.ConvTranspose2d(features*8, features*4, 2, stride=2)\n",
    "\n",
    "        self.layer7  = basic_block(features*8,features*2) \n",
    "        self.bn8     = nn.BatchNorm2d(features*2*2)\n",
    "        self.up3     = nn.ConvTranspose2d(features*4, features*2, 2, stride=2)   \n",
    "       \n",
    "        self.layer8  = basic_block(features*4,features) \n",
    "        self.bn9     = nn.BatchNorm2d(features*2)\n",
    "        self.up4     = nn.ConvTranspose2d(features*2, features*2, 2, stride=2)\n",
    "       \n",
    "        self.layer9  = basic_block(features*4,features)\n",
    "        self.out     = nn.Conv2d(features*2, 1, 1)\n",
    "       \n",
    "    def forward(self, x):\n",
    "    \n",
    "        layer1 = self.layer1(x)\n",
    "        down1  = F.relu(self.down1(layer1))\n",
    "\n",
    "        layer2 = self.layer2(down1) \n",
    "        down2  = F.relu(self.down2(layer2))\n",
    "       \n",
    "        layer3 = self.layer3(down2) \n",
    "        down3  = F.relu(self.down3(layer3))\n",
    "       \n",
    "        layer4 = self.layer4(down3) \n",
    "        down4  = F.relu(self.down4(layer4))\n",
    "       \n",
    "        bottleneck = self.bottleneck(down4)\n",
    "        up1     = F.relu(self.up1(self.bn6(bottleneck), output_size=layer4.size()))\n",
    "\n",
    "        merge1  = torch.cat([up1, layer4], dim=1)      \n",
    "        layer6  = self.layer6(merge1)\n",
    "        up2        = F.relu(self.up2(self.bn7(layer6), output_size=layer3.size()))\n",
    "\n",
    "        merge2     = torch.cat([up2, layer3], dim=1)\n",
    "        layer7     = self.layer7(merge2)\n",
    "        up3        = F.relu(self.up3(self.bn8(layer7), output_size=layer2.size()))\n",
    "        merge3     = torch.cat([up3, layer2], dim=1)\n",
    "        layer8  = self.layer8(merge3)\n",
    "        up4        = F.relu(self.up4(self.bn9(layer8), output_size=layer1.size()))\n",
    "       \n",
    "        merge4     = torch.cat([up4, layer1], dim=1)\n",
    "        layer9  = self.layer9(merge4)                    \n",
    "        out        = torch.sigmoid(self.out(layer9))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "dc16865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"best_epoch.pth\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93977f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
